braune_naacl2018.pdf:  lie Neveol, Mariana Neves, Martin Popel, Matt
chronopoulou_emnlp2020.pdf:  Névéol, Mariana Neves, Martin Popel, Matt Post,
deyringer_mtm2017.pdf:    The NMT systems marian3 and OpenNMT4 comprise implementations of asyn-
deyringer_mtm2017.pdf:chronous update strategies similar to Hogwild!. As marian is written in C++ and
deyringer_mtm2017.pdf:to the benchmarks listed on the website of marian.
deyringer_mtm2017.pdf:    3 https://marian-nmt.github.io
hangya_wmt2018.pdf:(ERC) under the European Union’s Horizon 2020            Martins, and Alexandra Birch. 2018. Marian: Fast
huck_eacl2017.pdf:  lie Neveol, Mariana Neves, Martin Popel, Matt             bec, Canada, August. Association for Computa-
huck_vardial2019.pdf:Barbara Plank, Anders Søgaard, and Yoav Goldberg.           Habibi, and Mariana Neves. 2017. Deep learning
huck_wmt2017.pdf:  lie Neveol, Mariana Neves, Martin Popel, Matt            tational Linguistics.
huck_wmt2017_system.pdf:  lie Neveol, Mariana Neves, Martin Popel, Matt
huck_wmt2017_system.pdf:  Models with Monolingual Data. In Proceedings           Antonio Jimeno Yepes, Aurélie Névéol, Mariana
huck_wmt2018.pdf:                                                          lie Neveol, Mariana Neves, Martin Popel, Matt
huck_wmt2018.pdf:Antonio Jimeno Yepes, Aurélie Névéol, Mariana
libovicky_emnlp2020.pdf:using Marian (Junczys-Dowmunt et al., 2018). We                        evaluate translation into Czech and German using
libovicky_emnlp2020.pdf:  ference on machine translation (WMT18). In Pro-            Martins, and Alexandra Birch. 2018. Marian: Fast
libovicky_emnlp2020.pdf:    tional Linguistics.                                  ian v1.7.0 (https://github.com/marian-nmt/
libovicky_emnlp2020.pdf:                                                         marian/releases/tag/1.7.0).
libovicky_findings_acl2022.pdf:                                                          Névéol, Mariana Neves, Martin Popel, Matt Post,
libovicky_findings_acl2022.pdf:Antonio Jimeno Yepes, Aurélie Névéol, Mariana                 5:365–378.
libovicky_wmt2020.pdf:et al., 2017) as implemented in Marian (Junczys-
libovicky_wmt2020.pdf:  2018a. A robust self-learning method for fully un-      Martins, and Alexandra Birch. 2018. Marian: Fast
riess_mtsummit2021.pdf:For our translation experiments we applied Marian (Junczys-Dowmunt et al., 2018) because
riess_mtsummit2021.pdf:state-of-the-art results. Marian is C++ based, which makes it very time efficient.
riess_mtsummit2021.pdf:  Germann, U., Fikri Aji, A., Bogoychev, N., Martins, A. F. T., and Birch, A. (2018). Marian: Fast neural
stojanovski_mtsummit2019.pdf:  ton Murray, Jeremy Gwinnup, Marianna J Mar-
stojanovski_system_wmt2018.pdf:  lie Neveol, Mariana Neves, Martin Popel, Matt          322.
wellerdimarco_wmt2022_task.pdf:           DE-PL (66.5M),                   with sampling           (40k)              Marian
